import streamlit as st
import pandas as pd
import io
import csv

# ==========================================
# ğŸ¨ é¡µé¢é…ç½®ä¸ CSS æ ·å¼ (Luckin é£æ ¼)
# ==========================================
st.set_page_config(page_title="ç‘å¹¸å’–å•¡è´¢åŠ¡å¯¹è´¦ç³»ç»Ÿ", layout="wide", page_icon="â˜•")

luckin_blue = "#0022AB"

st.markdown(f"""
    <style>
    .main {{ font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }}
    .stButton>button {{
        background-color: {luckin_blue}; color: white; border-radius: 5px;
        height: 3em; width: 100%; font-weight: bold; border: none;
    }}
    .stButton>button:hover {{ background-color: #00187A; color: white; }}
    h1, h2, h3 {{ color: #333333; }}
    .stAlert {{ background-color: #EEF4FF; border-left: 5px solid {luckin_blue}; }}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ§  æ ¸å¿ƒé€»è¾‘ & æ˜ å°„
# ==========================================

# å®˜æ–¹é—¨åº—IDæ˜ å°„
STORE_ID_MAP = {
    'US00001': 'US00001 - Broadway (755)',
    'US00002': 'US00002 - 6th Ave (800)',
    'US00003': 'US00003 - Maiden Lane (100)',
    'US00004': 'US00004 - 37th St',
    'US00005': 'US00005 - 8th Ave (901)',
    'US00006': 'US00006 - Fulton St (102)',
}

# Uber location name mapping
UBER_LOCATION_MAP = {
    'broadway': 'US00001',
    '6th ave': 'US00002',
    'sixth ave': 'US00002',
    'maiden': 'US00003',
    '37th': 'US00004',
    '8th ave': 'US00005',
    'eighth ave': 'US00005',
    'fulton': 'US00006',
}

def extract_store_id(raw_text, platform='generic'):
    """Extract standardized store ID from various platform formats"""
    if pd.isna(raw_text):
        return 'æœªçŸ¥é—¨åº—'
    
    text = str(raw_text).strip()
    text_lower = text.lower()
    
    # Check for direct US000XX pattern
    import re
    match = re.search(r'US0000[1-6]', text, re.IGNORECASE)
    if match:
        store_id = match.group().upper()
        return STORE_ID_MAP.get(store_id, store_id)
    
    # Platform-specific mapping
    if platform == 'uber':
        for key, store_id in UBER_LOCATION_MAP.items():
            if key in text_lower:
                return STORE_ID_MAP.get(store_id, store_id)
    
    # Address-based mapping for Grubhub
    address_map = {
        '755': 'US00001', 'broadway': 'US00001',
        '800': 'US00002', '6th': 'US00002',
        '100': 'US00003', 'maiden': 'US00003',
        '37': 'US00004',
        '901': 'US00005', '8th': 'US00005',
        '102': 'US00006', 'fulton': 'US00006',
    }
    
    for key, store_id in address_map.items():
        if key in text_lower:
            return STORE_ID_MAP.get(store_id, store_id)
    
    return text[:30] if len(text) > 30 else text

def clean_num(x):
    """Convert various number formats to float"""
    if isinstance(x, (int, float)):
        return x
    try:
        clean = str(x).replace(',', '').replace('$', '').replace(' ', '').strip()
        return float(clean) if clean else 0.0
    except:
        return 0.0

def find_header_row(uploaded_file, target_columns):
    """Find the row containing column headers"""
    uploaded_file.seek(0)
    try:
        content = uploaded_file.getvalue().decode('utf-8', errors='replace').splitlines()
        reader = csv.reader(content)
        for i, row in enumerate(reader):
            clean_row = [str(x).strip() for x in row]
            matches = sum(1 for col in target_columns if col in clean_row)
            if matches >= 2:
                uploaded_file.seek(0)
                return i
    except Exception:
        return None
    return None

# ==========================================
# ğŸŸ¦ å¹³å°æ•°æ®å¤„ç† - ä¿®æ­£ç‰ˆï¼ˆè´¹ç”¨è½¬æ­£æ•°ï¼‰
# ==========================================

def process_ubereats(uploaded_file):
    """Process UberEats CSV - fees converted to positive values"""
    target_cols = ['é¤å…åç§°', 'é”€å”®é¢ï¼ˆä¸å«ç¨è´¹ï¼‰', 'å¹³å°æœåŠ¡è´¹']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None:
        return None

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    # Date filter - October 2025 only
    if 'è®¢å•æ—¥æœŸ' in df.columns:
        df['Date'] = pd.to_datetime(df['è®¢å•æ—¥æœŸ'], format='%m/%d/%Y', errors='coerce')
        df = df[(df['Date'] >= '2025-10-01') & (df['Date'] <= '2025-10-31')]
    
    def get_col(col_name):
        return df[col_name].apply(clean_num) if col_name in df.columns else pd.Series([0.0] * len(df))

    # æ”¶å…¥é¡¹ï¼ˆæ­£æ•°ï¼‰
    df['Gross_Sales'] = get_col('é”€å”®é¢ï¼ˆä¸å«ç¨è´¹ï¼‰')
    df['Tax_Collected'] = get_col('é”€å”®é¢ç¨è´¹')
    
    # è´¹ç”¨é¡¹ï¼ˆåŸå§‹è´Ÿæ•° â†’ å–ç»å¯¹å€¼ï¼‰
    df['Discount'] = get_col('å•†å“ä¼˜æƒ ï¼ˆå«ç¨ï¼‰').abs()  # æŠ˜æ‰£æ”¯å‡º
    df['Commission'] = get_col('å¹³å°æœåŠ¡è´¹').abs()  # å¹³å°ä½£é‡‘
    df['Order_Error'] = get_col('è®¢å•é”™è¯¯è°ƒæ•´é¢').abs()  # è®¢å•é”™è¯¯
    
    # è¡¥è´´/è¿”è¿˜ï¼ˆæ­£æ•°æ”¶å…¥ï¼‰
    df['Marketing_Credit'] = get_col('è¥é”€è°ƒæ•´é¢')  # Uberç»™çš„è¥é”€è¡¥è´´
    
    # å‡€å…¥è´¦ = ä½¿ç”¨column 26 (è°ƒæ•´åçš„æ€»é”€å”®é¢å«ç¨è´¹) ä¸ Analytics ä¿æŒä¸€è‡´
    # ä½†è¿™é‡Œæˆ‘ä»¬é‡æ–°è®¡ç®—ä»¥ä¾¿ç†è§£
    df['Calculated_Net'] = (df['Gross_Sales'] + df['Tax_Collected'] 
                           - df['Discount'] - df['Commission'] 
                           - df['Order_Error'] + df['Marketing_Credit'])
    
    # å®é™…å‡€å…¥è´¦ï¼ˆæ¥è‡ªCSVï¼‰
    df['Net_Payout'] = get_col('æ”¶å…¥æ€»é¢')
    
    df['Vendor'] = 'UberEats'
    df['Store_Standard'] = df['é¤å…åç§°'].apply(lambda x: extract_store_id(x, 'uber'))
    
    return df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Tax_Collected', 
               'Discount', 'Commission', 'Marketing_Credit', 'Order_Error', 
               'Calculated_Net', 'Net_Payout']]

def process_doordash(uploaded_file):
    """Process DoorDash CSV - fees converted to positive values"""
    target_cols = ['åº—é“ºåç§°', 'å°è®¡', 'ä½£é‡‘']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None:
        return None

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    # Date filter - October 2025 only
    if 'æ—¶é—´æˆ³æœ¬åœ°æ—¥æœŸ' in df.columns:
        df['Date'] = pd.to_datetime(df['æ—¶é—´æˆ³æœ¬åœ°æ—¥æœŸ'], format='%m/%d/%Y', errors='coerce')
        df = df[(df['Date'] >= '2025-10-01') & (df['Date'] <= '2025-10-31')]
    
    def get_col(col_name):
        matches = [c for c in df.columns if col_name in c]
        if matches:
            return df[matches[0]].apply(clean_num)
        return pd.Series([0.0] * len(df))

    # æ”¶å…¥é¡¹
    df['Gross_Sales'] = get_col('å°è®¡')
    df['Tax_Collected'] = get_col('ç¨æ¬¾å°è®¡')
    
    # è´¹ç”¨é¡¹ï¼ˆå–ç»å¯¹å€¼ï¼‰
    df['Discount'] = get_col('ç”±æ‚¨å‡ºèµ„').abs()  # å•†å®¶æ‰¿æ‹…çš„æŠ˜æ‰£
    df['Commission'] = get_col('ä½£é‡‘').abs()  # ä½£é‡‘
    df['Marketing_Fee'] = get_col('è¥é”€è´¹').abs()  # è¥é”€è´¹
    df['Order_Error'] = get_col('é”™è¯¯è´¹ç”¨').abs()
    
    # è¡¥è´´/è¿”è¿˜
    df['Marketing_Credit'] = get_col('è¥é”€ç§¯åˆ†')  # DoorDashç»™çš„ç§¯åˆ†
    df['DD_Funded'] = get_col('ç”± DoorDash å‡ºèµ„').abs()  # DDæ‰¿æ‹…çš„æŠ˜æ‰£ï¼ˆå¯¹å•†å®¶æ˜¯å¥½äº‹ï¼‰
    
    # åˆå¹¶è´¹ç”¨ç±»
    df['Total_Discount'] = df['Discount']
    df['Total_Commission'] = df['Commission']
    df['Total_Marketing'] = df['Marketing_Fee']
    df['Total_Credit'] = df['Marketing_Credit'] + df['DD_Funded']
    
    # å‡€å…¥è´¦
    df['Net_Payout'] = get_col('å‡€æ€»è®¡')
    
    df['Vendor'] = 'DoorDash'
    df['Store_Standard'] = df['åº—é“ºåç§°'].apply(lambda x: extract_store_id(x, 'doordash'))
    
    return df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Tax_Collected',
               'Total_Discount', 'Total_Commission', 'Total_Marketing', 
               'Total_Credit', 'Order_Error', 'Net_Payout']]

def process_grubhub(uploaded_file):
    """Process Grubhub CSV - fees converted to positive values"""
    target_cols = ['store_name', 'subtotal', 'commission']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None:
        return None

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    # Date filter - October 2025 only (exclude records with invalid dates)
    if 'transaction_date' in df.columns:
        df['Date'] = pd.to_datetime(df['transaction_date'], format='%m/%d/%Y', errors='coerce')
        df = df[(df['Date'] >= '2025-10-01') & (df['Date'] <= '2025-10-31')]
    
    def get_col(col_name):
        return df[col_name].apply(clean_num) if col_name in df.columns else pd.Series([0.0] * len(df))

    # æ”¶å…¥é¡¹
    df['Gross_Sales'] = get_col('subtotal')
    df['Tax_Collected'] = get_col('subtotal_sales_tax')
    
    # è´¹ç”¨é¡¹ï¼ˆå–ç»å¯¹å€¼ï¼‰
    df['Commission'] = get_col('commission').abs()
    df['Delivery_Commission'] = get_col('delivery_commission').abs()
    df['Processing_Fee'] = get_col('processing_fee').abs()
    df['Merchant_Promo'] = get_col('merchant_funded_promotion').abs()
    df['Merchant_Loyalty'] = get_col('merchant_funded_loyalty').abs()
    
    # åˆå¹¶
    df['Total_Discount'] = df['Merchant_Promo'] + df['Merchant_Loyalty']
    df['Total_Commission'] = df['Commission'] + df['Delivery_Commission']
    df['Total_Processing'] = df['Processing_Fee']
    
    # å‡€å…¥è´¦
    df['Net_Payout'] = get_col('merchant_net_total')
    
    df['Vendor'] = 'Grubhub'
    # Use street_address for store identification
    store_info = df['store_name'].astype(str) + " " + df.get('street_address', pd.Series(['']*len(df))).astype(str)
    df['Store_Standard'] = store_info.apply(lambda x: extract_store_id(x, 'grubhub'))
    
    return df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Tax_Collected',
               'Total_Discount', 'Total_Commission', 'Total_Processing', 'Net_Payout']]

# ==========================================
# ğŸ–¥ï¸ STREAMLIT UI
# ==========================================

# Logo loading - use relative path for Streamlit Cloud deployment
import os
logo_path = os.path.join(os.path.dirname(__file__), "logo.png")
if os.path.exists(logo_path):
    col_logo, col_title = st.columns([1, 4])
    with col_logo:
        st.image(logo_path, width=120)
    with col_title:
        st.markdown(f"<h1 style='color:{luckin_blue}; margin-top: 20px;'>luckin coffee</h1>", unsafe_allow_html=True)
        st.markdown("## è´¢åŠ¡å¯¹è´¦è‡ªåŠ¨åŒ–å¹³å° v4.0")
else:
    st.markdown(f"<h1 style='color:{luckin_blue};'>â˜• luckin coffee</h1>", unsafe_allow_html=True)
    st.markdown("## è´¢åŠ¡å¯¹è´¦è‡ªåŠ¨åŒ–å¹³å° v4.0")
st.markdown("### è´¹ç”¨æ˜ç»†åˆ†æ (Fee Breakdown Analysis)")
st.markdown("---")

# ä¾§è¾¹æ è¯´æ˜
with st.sidebar:
    st.header("ğŸ“˜ ä½¿ç”¨è¯´æ˜")
    st.info("""
    **Version 4.0 æ›´æ–°:**
    - âœ… è´¹ç”¨æ˜¾ç¤ºä¸ºæ­£æ•°ï¼ˆæ”¯å‡ºï¼‰
    - âœ… æ¸…æ™°åŒºåˆ†å„ç±»è´¹ç”¨
    - âœ… ä¸ Analytics App æ•°æ®å¯¹é½
    - âœ… ä»…ç»Ÿè®¡10æœˆæ•°æ®
    """)
    
    st.markdown("### ğŸ’¡ æ•°æ®è¯´æ˜")
    st.markdown("""
    **CSVåŸå§‹æ•°æ®è§„åˆ™:**
    - è´Ÿæ•° = å¹³å°æ‰£æ¬¾ï¼ˆè´¹ç”¨ï¼‰
    - æ­£æ•° = æ”¶å…¥æˆ–è¡¥è´´
    
    **æœ¬æŠ¥è¡¨æ˜¾ç¤ºè§„åˆ™:**
    - è´¹ç”¨å…¨éƒ¨æ˜¾ç¤ºä¸º**æ­£æ•°**
    - æ–¹ä¾¿ä¼šè®¡ç†è§£å’Œå…¥è´¦
    """)

# ä¸Šä¼ åŒºåŸŸ
st.subheader("ğŸ“‚ è¯·ä¸Šä¼ å¹³å°è´¦å• (CSV)")
col1, col2, col3 = st.columns(3)

with col1:
    uber_file = st.file_uploader("UberEats è´¦å•", type=['csv'])
with col2:
    dd_file = st.file_uploader("DoorDash è´¦å•", type=['csv'])
with col3:
    gh_file = st.file_uploader("Grubhub è´¦å•", type=['csv'])

st.markdown("<br>", unsafe_allow_html=True)

if st.button("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–å¯¹è´¦å¤„ç†", type="primary"):
    results = {'UberEats': None, 'DoorDash': None, 'Grubhub': None}
    
    my_bar = st.progress(0)
    
    if uber_file:
        results['UberEats'] = process_ubereats(uber_file)
        if results['UberEats'] is None:
            st.error("âŒ UberEats æ–‡ä»¶æ ¼å¼é”™è¯¯")
    my_bar.progress(30)
    
    if dd_file:
        results['DoorDash'] = process_doordash(dd_file)
        if results['DoorDash'] is None:
            st.error("âŒ DoorDash æ–‡ä»¶æ ¼å¼é”™è¯¯")
    my_bar.progress(60)
    
    if gh_file:
        results['Grubhub'] = process_grubhub(gh_file)
        if results['Grubhub'] is None:
            st.error("âŒ Grubhub æ–‡ä»¶æ ¼å¼é”™è¯¯")
    my_bar.progress(90)
    
    if all(v is None for v in results.values()):
        st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæœ‰æ•ˆçš„ CSV æ–‡ä»¶ã€‚")
        my_bar.empty()
    else:
        my_bar.progress(100)
        st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼")
        
        # ==========================================
        # ğŸ“Š åˆ†å¹³å°è¯¦ç»†æŠ¥å‘Š
        # ==========================================
        
        for platform, df in results.items():
            if df is not None and len(df) > 0:
                st.markdown(f"---")
                st.subheader(f"ğŸ“Š {platform} è´¹ç”¨æ˜ç»†")
                
                # æ±‡æ€»ç»Ÿè®¡
                summary_data = {
                    'è®¢å•æ•°': len(df),
                    'é”€å”®é¢ (Gross)': df['Gross_Sales'].sum(),
                    'ç¨è´¹æ”¶å…¥': df['Tax_Collected'].sum(),
                }
                
                if platform == 'UberEats':
                    summary_data.update({
                        'ğŸ’¸ æŠ˜æ‰£æ”¯å‡º': df['Discount'].sum(),
                        'ğŸ’¸ å¹³å°ä½£é‡‘': df['Commission'].sum(),
                        'ğŸ’° è¥é”€è¡¥è´´ (æ”¶å…¥)': df['Marketing_Credit'].sum(),
                        'ğŸ’¸ è®¢å•é”™è¯¯': df['Order_Error'].sum(),
                        'å‡€å…¥è´¦': df['Net_Payout'].sum(),
                    })
                    
                elif platform == 'DoorDash':
                    summary_data.update({
                        'ğŸ’¸ æŠ˜æ‰£æ”¯å‡º (å•†å®¶)': df['Total_Discount'].sum(),
                        'ğŸ’¸ å¹³å°ä½£é‡‘': df['Total_Commission'].sum(),
                        'ğŸ’¸ è¥é”€è´¹': df['Total_Marketing'].sum(),
                        'ğŸ’° å¹³å°è¡¥è´´ (æ”¶å…¥)': df['Total_Credit'].sum(),
                        'å‡€å…¥è´¦': df['Net_Payout'].sum(),
                    })
                    
                elif platform == 'Grubhub':
                    summary_data.update({
                        'ğŸ’¸ æŠ˜æ‰£æ”¯å‡º': df['Total_Discount'].sum(),
                        'ğŸ’¸ ä½£é‡‘åˆè®¡': df['Total_Commission'].sum(),
                        'ğŸ’¸ å¤„ç†è´¹': df['Total_Processing'].sum(),
                        'å‡€å…¥è´¦': df['Net_Payout'].sum(),
                    })
                
                # æ˜¾ç¤ºæ±‡æ€»å¡ç‰‡
                cols = st.columns(4)
                for i, (key, val) in enumerate(summary_data.items()):
                    with cols[i % 4]:
                        if isinstance(val, (int, float)):
                            if 'è®¢å•' in key:
                                st.metric(key, f"{int(val):,}")
                            elif 'ğŸ’¸' in key:
                                st.metric(key, f"${val:,.2f}", delta=None)
                            elif 'ğŸ’°' in key:
                                st.metric(key, f"${val:,.2f}", delta="è¡¥è´´")
                            else:
                                st.metric(key, f"${val:,.2f}")
        
        # ==========================================
        # ğŸ“Š ä¸‰å¹³å°æ±‡æ€»
        # ==========================================
        st.markdown("---")
        st.subheader("ğŸ“Š ä¸‰å¹³å°è´¹ç”¨æ±‡æ€»")
        
        total_orders = sum(len(df) for df in results.values() if df is not None)
        total_gross = sum(df['Gross_Sales'].sum() for df in results.values() if df is not None)
        total_net = sum(df['Net_Payout'].sum() for df in results.values() if df is not None)
        
        # è®¡ç®—å„ç±»è´¹ç”¨æ€»å’Œ
        total_discount = 0
        total_commission = 0
        total_marketing = 0
        total_processing = 0
        total_credit = 0
        
        if results['UberEats'] is not None:
            df = results['UberEats']
            total_discount += df['Discount'].sum()
            total_commission += df['Commission'].sum()
            total_credit += df['Marketing_Credit'].sum()
        
        if results['DoorDash'] is not None:
            df = results['DoorDash']
            total_discount += df['Total_Discount'].sum()
            total_commission += df['Total_Commission'].sum()
            total_marketing += df['Total_Marketing'].sum()
            total_credit += df['Total_Credit'].sum()
        
        if results['Grubhub'] is not None:
            df = results['Grubhub']
            total_discount += df['Total_Discount'].sum()
            total_commission += df['Total_Commission'].sum()
            total_processing += df['Total_Processing'].sum()
        
        st.markdown(f"""
        ### ğŸ“ˆ è´¹ç”¨æ±‡æ€»è¡¨ (10æœˆ)
        
        | é¡¹ç›® | é‡‘é¢ | è¯´æ˜ |
        |------|------|------|
        | **æ€»è®¢å•æ•°** | {total_orders:,} | ä¸‰å¹³å°åˆè®¡ |
        | **é”€å”®æ€»é¢** | ${total_gross:,.2f} | Gross Sales (ä¸å«ç¨) |
        | **ğŸ’¸ æŠ˜æ‰£/ä¿ƒé”€** | ${total_discount:,.2f} | å•†å®¶æ‰¿æ‹…çš„ä¿ƒé”€æˆæœ¬ |
        | **ğŸ’¸ å¹³å°ä½£é‡‘** | ${total_commission:,.2f} | å„å¹³å°æœåŠ¡è´¹ |
        | **ğŸ’¸ è¥é”€è´¹** | ${total_marketing:,.2f} | å¹¿å‘Š/æ¨å¹¿è´¹ç”¨ |
        | **ğŸ’¸ å¤„ç†è´¹** | ${total_processing:,.2f} | æ”¯ä»˜å¤„ç†è´¹ |
        | **ğŸ’° å¹³å°è¡¥è´´** | ${total_credit:,.2f} | å¹³å°ç»™çš„è¥é”€è¿”è¿˜ |
        | **è´¹ç”¨å‡€é¢** | ${(total_discount + total_commission + total_marketing + total_processing - total_credit):,.2f} | æ‰£é™¤è¡¥è´´åçš„å®é™…è´¹ç”¨ |
        | **å‡€å…¥è´¦** | ${total_net:,.2f} | å®é™…æ”¶åˆ°é‡‘é¢ |
        """)
        
        # è´¹ç‡åˆ†æ
        if total_gross > 0:
            st.markdown("### ğŸ“Š è´¹ç‡åˆ†æ")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æŠ˜æ‰£ç‡", f"{(total_discount/total_gross)*100:.1f}%")
            with col2:
                st.metric("ä½£é‡‘ç‡", f"{(total_commission/total_gross)*100:.1f}%")
            with col3:
                st.metric("è¥é”€è´¹ç‡", f"{(total_marketing/total_gross)*100:.1f}%")
            with col4:
                net_rate = (total_net / total_gross) * 100
                st.metric("å‡€æ”¶å…¥ç‡", f"{net_rate:.1f}%")
        
        # ==========================================
        # ğŸ“¥ Excel å¯¼å‡º
        # ==========================================
        st.markdown("---")
        st.subheader("ğŸ“¥ å¯¼å‡ºæŠ¥è¡¨")
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            wb = writer.book
            
            # æ ¼å¼å®šä¹‰
            fmt_header = wb.add_format({
                'bold': True, 'bg_color': '#0022AB', 'font_color': 'white',
                'border': 1, 'align': 'center', 'valign': 'vcenter'
            })
            fmt_currency = wb.add_format({'num_format': '$#,##0.00'})
            fmt_expense = wb.add_format({'num_format': '$#,##0.00', 'font_color': '#C00000'})
            fmt_income = wb.add_format({'num_format': '$#,##0.00', 'font_color': '#008000'})
            
            # Sheet 1: è´¹ç”¨æ±‡æ€»
            summary_rows = [
                ['é¡¹ç›®', 'UberEats', 'DoorDash', 'Grubhub', 'åˆè®¡'],
                ['è®¢å•æ•°', 
                 len(results['UberEats']) if results['UberEats'] is not None else 0,
                 len(results['DoorDash']) if results['DoorDash'] is not None else 0,
                 len(results['Grubhub']) if results['Grubhub'] is not None else 0,
                 total_orders],
                ['é”€å”®æ€»é¢',
                 results['UberEats']['Gross_Sales'].sum() if results['UberEats'] is not None else 0,
                 results['DoorDash']['Gross_Sales'].sum() if results['DoorDash'] is not None else 0,
                 results['Grubhub']['Gross_Sales'].sum() if results['Grubhub'] is not None else 0,
                 total_gross],
            ]
            
            # Add fee breakdowns
            uber_discount = results['UberEats']['Discount'].sum() if results['UberEats'] is not None else 0
            dd_discount = results['DoorDash']['Total_Discount'].sum() if results['DoorDash'] is not None else 0
            gh_discount = results['Grubhub']['Total_Discount'].sum() if results['Grubhub'] is not None else 0
            
            uber_comm = results['UberEats']['Commission'].sum() if results['UberEats'] is not None else 0
            dd_comm = results['DoorDash']['Total_Commission'].sum() if results['DoorDash'] is not None else 0
            gh_comm = results['Grubhub']['Total_Commission'].sum() if results['Grubhub'] is not None else 0
            
            dd_mkt = results['DoorDash']['Total_Marketing'].sum() if results['DoorDash'] is not None else 0
            gh_proc = results['Grubhub']['Total_Processing'].sum() if results['Grubhub'] is not None else 0
            
            uber_credit = results['UberEats']['Marketing_Credit'].sum() if results['UberEats'] is not None else 0
            dd_credit = results['DoorDash']['Total_Credit'].sum() if results['DoorDash'] is not None else 0
            
            uber_net = results['UberEats']['Net_Payout'].sum() if results['UberEats'] is not None else 0
            dd_net = results['DoorDash']['Net_Payout'].sum() if results['DoorDash'] is not None else 0
            gh_net = results['Grubhub']['Net_Payout'].sum() if results['Grubhub'] is not None else 0
            
            summary_rows.extend([
                ['æŠ˜æ‰£/ä¿ƒé”€ (æ”¯å‡º)', uber_discount, dd_discount, gh_discount, total_discount],
                ['å¹³å°ä½£é‡‘ (æ”¯å‡º)', uber_comm, dd_comm, gh_comm, total_commission],
                ['è¥é”€è´¹ (æ”¯å‡º)', 0, dd_mkt, 0, total_marketing],
                ['å¤„ç†è´¹ (æ”¯å‡º)', 0, 0, gh_proc, total_processing],
                ['å¹³å°è¡¥è´´ (æ”¶å…¥)', uber_credit, dd_credit, 0, total_credit],
                ['å‡€å…¥è´¦', uber_net, dd_net, gh_net, total_net],
            ])
            
            summary_df = pd.DataFrame(summary_rows[1:], columns=summary_rows[0])
            summary_df.to_excel(writer, sheet_name='è´¹ç”¨æ±‡æ€»', index=False, startrow=1)
            
            ws1 = writer.sheets['è´¹ç”¨æ±‡æ€»']
            for col, h in enumerate(summary_rows[0]):
                ws1.write(0, col, h, fmt_header)
            ws1.set_column('A:A', 20)
            ws1.set_column('B:E', 15, fmt_currency)
            
            # Sheet 2: å„å¹³å°æ˜ç»†
            for platform, df in results.items():
                if df is not None:
                    df.to_excel(writer, sheet_name=f'{platform}æ˜ç»†', index=False)
        
        output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ Excel å¯¹è´¦æŠ¥è¡¨",
            data=output,
            file_name="Luckin_Fee_Breakdown_Report_v4.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        
        st.info("""
        **æŠ¥è¡¨è¯´æ˜:**
        - ğŸ’¸ æ ‡è®°çš„è´¹ç”¨é¡¹æ˜¾ç¤ºä¸º**æ­£æ•°**ï¼ˆä»£è¡¨æ”¯å‡ºï¼‰
        - ğŸ’° æ ‡è®°çš„è¡¥è´´é¡¹æ˜¾ç¤ºä¸º**æ­£æ•°**ï¼ˆä»£è¡¨æ”¶å…¥ï¼‰
        - å‡€å…¥è´¦ = CSVä¸­å¹³å°æŠ¥å‘Šçš„å®é™…å…¥è´¦é‡‘é¢
        """)
