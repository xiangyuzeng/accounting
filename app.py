import streamlit as st
import pandas as pd
import io
import csv

# ==========================================
# ğŸ¨ é¡µé¢é…ç½®ä¸ CSS æ ·å¼ (Luckin é£æ ¼)
# ==========================================
st.set_page_config(page_title="ç‘å¹¸å’–å•¡è´¢åŠ¡å¯¹è´¦ç³»ç»Ÿ", layout="wide", page_icon="â˜•")

luckin_blue = "#0022AB"

st.markdown(f"""
    <style>
    .main {{
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
    }}
    .stButton>button {{
        background-color: {luckin_blue};
        color: white;
        border-radius: 5px;
        height: 3em;
        width: 100%;
        font-weight: bold;
        border: none;
    }}
    .stButton>button:hover {{
        background-color: #00187A;
        color: white;
    }}
    h1, h2, h3 {{
        color: #333333;
    }}
    .stAlert {{
        background-color: #EEF4FF;
        border-left: 5px solid {luckin_blue};
    }}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ§  æ ¸å¿ƒé€»è¾‘ & é—¨åº—æ˜ å°„
# ==========================================

# æ ‡å‡†é—¨åº—IDæ˜ å°„ (å®˜æ–¹å®šä¹‰)
STORE_ID_DISPLAY = {
    'US00001': 'US00001 - Broadway (ç™¾è€æ±‡åº—)',
    'US00002': 'US00002 - 6th Ave (ç¬¬å…­å¤§é“åº—)',
    'US00003': 'US00003 - Maiden Lane (æ¢…ç™»å··åº—)',
    'US00004': 'US00004 - 37th St (37è¡—åº—)',
    'US00005': 'US00005 - 8th Ave (ç¬¬å…«å¤§é“åº—)',
    'US00006': 'US00006 - Fulton St (å¯Œå°”é¡¿è¡—åº—)'
}

def normalize_store_doordash(raw_text):
    """DoorDash: ä»åº—é“ºåç§°ä¸­æå–é—¨åº—ID (å¦‚ 'Luckin Coffee US00002' -> 'US00001')"""
    if pd.isna(raw_text):
        return 'æœªçŸ¥é—¨åº—'
    text = str(raw_text).upper().replace(' ', '')
    
    # åŒ¹é… US00001-US00006
    for store_id in STORE_ID_DISPLAY.keys():
        if store_id.replace(' ', '') in text:
            return STORE_ID_DISPLAY[store_id]
    
    return str(raw_text)

def normalize_store_uber(raw_text):
    """Uber: ä»é¤å…åç§°ä¸­æå–é—¨åº— (å¦‚ 'Luckin Coffee (Broadway)' -> 'US00001')"""
    if pd.isna(raw_text):
        return 'æœªçŸ¥é—¨åº—'
    text_lower = str(raw_text).lower()
    
    # Uber é—¨åº—åç§°æ˜ å°„åˆ°æ ‡å‡†ID
    if 'broadway' in text_lower:
        return STORE_ID_DISPLAY['US00001']
    elif '6th' in text_lower:
        return STORE_ID_DISPLAY['US00002']
    elif 'maiden' in text_lower:
        return STORE_ID_DISPLAY['US00003']
    elif '37th' in text_lower:
        return STORE_ID_DISPLAY['US00004']
    elif '8th' in text_lower:
        return STORE_ID_DISPLAY['US00005']
    elif 'fulton' in text_lower:
        return STORE_ID_DISPLAY['US00006']
    
    return str(raw_text)

def normalize_store_grubhub(store_number, street_address):
    """Grubhub: ä¼˜å…ˆä½¿ç”¨åœ°å€åˆ¤æ–­é—¨åº— (å› ä¸ºGrubhubçš„store_numberä¸ä¸€è‡´)"""
    address = str(street_address).lower() if not pd.isna(street_address) else ''
    
    # æ ¹æ®å®é™…åœ°å€æ˜ å°„åˆ°æ ‡å‡†é—¨åº—ID
    if '755' in address or 'broadway' in address:
        return STORE_ID_DISPLAY['US00001']
    elif '800' in address or '6th' in address:
        return STORE_ID_DISPLAY['US00002']
    elif '100' in address or 'maiden' in address:
        return STORE_ID_DISPLAY['US00003']
    elif '37th' in address:
        return STORE_ID_DISPLAY['US00004']
    elif '901' in address or '8th' in address:
        return STORE_ID_DISPLAY['US00005']
    elif '102' in address or 'fulton' in address:
        return STORE_ID_DISPLAY['US00006']
    
    # å¦‚æœåœ°å€æ— æ³•è¯†åˆ«ï¼Œå°è¯•ç”¨store_number
    store_num = str(store_number).upper().replace(' ', '') if not pd.isna(store_number) else ''
    for store_id in STORE_ID_DISPLAY.keys():
        if store_id in store_num:
            return STORE_ID_DISPLAY[store_id]
    
    return f'æœªçŸ¥é—¨åº— ({store_number})'

def clean_num(x):
    """æ¸…æ´—æ•°å­—å­—æ®µ"""
    if isinstance(x, (int, float)):
        return x
    try:
        clean = str(x).replace(',', '').replace('$', '').replace(' ', '').strip()
        return float(clean) if clean else 0.0
    except:
        return 0.0

def find_header_row(uploaded_file, target_columns):
    """æŸ¥æ‰¾CSVè¡¨å¤´è¡Œ"""
    uploaded_file.seek(0)
    try:
        content = uploaded_file.getvalue().decode('utf-8', errors='replace').splitlines()
        reader = csv.reader(content)
        for i, row in enumerate(reader):
            clean_row = [str(x).strip() for x in row]
            matches = sum(1 for col in target_columns if col in clean_row)
            if matches >= 2:
                uploaded_file.seek(0)
                return i
    except Exception:
        return None
    return None

# ==========================================
# ğŸŸ¦ å¹³å°æ•°æ®å¤„ç†
# ==========================================

def process_ubereats(uploaded_file):
    """å¤„ç† UberEats æ•°æ®"""
    target_cols = ['é¤å…åç§°', 'é”€å”®é¢ï¼ˆä¸å«ç¨è´¹ï¼‰', 'å¹³å°æœåŠ¡è´¹']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None:
        return None, "æœªæ‰¾åˆ°æœ‰æ•ˆè¡¨å¤´"

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    def get_col(col_name):
        return df[col_name].apply(clean_num) if col_name in df.columns else 0.0

    df['Gross_Sales'] = get_col('é”€å”®é¢ï¼ˆä¸å«ç¨è´¹ï¼‰')
    df['Merchant_Promo'] = get_col('å•†å“ä¼˜æƒ ï¼ˆå«ç¨ï¼‰') 
    df['Commission'] = get_col('å¹³å°æœåŠ¡è´¹')
    df['Marketing'] = get_col('è¥é”€è°ƒæ•´é¢') + get_col('å¹¿å‘Šæ”¯å‡º')
    df['Tax_Adj'] = get_col('é”€å”®é¢ç¨è´¹') + get_col('å¹³å°ä»£ç¼´ç¨')
    df['Other_Fees'] = get_col('è®¢å•é”™è¯¯è°ƒæ•´é¢') + get_col('æ´¾é€ç½‘ç»œè´¹')
    df['Net_Payout'] = get_col('æ”¶å…¥æ€»é¢')
    
    df['Vendor'] = 'UberEats'
    df['Store_Standard'] = df['é¤å…åç§°'].apply(normalize_store_uber)
    
    result = df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout']]
    return result, f"âœ… UberEats: æˆåŠŸå¤„ç† {len(result)} æ¡è®°å½•"

def process_doordash(uploaded_file):
    """å¤„ç† DoorDash æ•°æ®"""
    target_cols = ['åº—é“ºåç§°', 'å°è®¡', 'ä½£é‡‘']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None:
        return None, "æœªæ‰¾åˆ°æœ‰æ•ˆè¡¨å¤´"

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    def get_col(col_name):
        matches = [c for c in df.columns if col_name in c]
        if matches:
            return df[matches[0]].apply(clean_num)
        return 0.0

    df['Gross_Sales'] = get_col('å°è®¡')
    df['Merchant_Promo'] = get_col('ç”±æ‚¨å‡ºèµ„') 
    df['Commission'] = get_col('ä½£é‡‘')
    df['Marketing'] = get_col('è¥é”€è´¹') + get_col('è¥é”€ç§¯åˆ†')
    df['Tax_Adj'] = get_col('ç¨æ¬¾å°è®¡')
    df['Other_Fees'] = get_col('é”™è¯¯è´¹ç”¨') + get_col('è°ƒæ•´')
    df['Net_Payout'] = get_col('å‡€æ€»è®¡')
    
    df['Vendor'] = 'DoorDash'
    df['Store_Standard'] = df['åº—é“ºåç§°'].apply(normalize_store_doordash)
    
    result = df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout']]
    return result, f"âœ… DoorDash: æˆåŠŸå¤„ç† {len(result)} æ¡è®°å½•"

def process_grubhub(uploaded_file):
    """å¤„ç† Grubhub æ•°æ® (å«æ—¥æœŸä¿®å¤é€»è¾‘)"""
    target_cols = ['store_name', 'subtotal', 'commission']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None:
        return None, "æœªæ‰¾åˆ°æœ‰æ•ˆè¡¨å¤´"

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    def get_col(col_name):
        return df[col_name].apply(clean_num) if col_name in df.columns else 0.0

    # å¤„ç†æ—¥æœŸ (ä¸åˆ†æç³»ç»Ÿä¿æŒä¸€è‡´çš„é€»è¾‘)
    warning_msg = ""
    if 'transaction_date' in df.columns:
        df['Date'] = pd.to_datetime(df['transaction_date'], format='%m/%d/%Y', errors='coerce')
        if df['Date'].isna().all():
            warning_msg = " âš ï¸ æ—¥æœŸæ•°æ®å¼‚å¸¸ï¼Œå·²æŒ‰è®°å½•é¡ºåºå¤„ç†"

    df['Gross_Sales'] = get_col('subtotal')
    df['Merchant_Promo'] = get_col('merchant_funded_promotion') + get_col('merchant_funded_loyalty')
    df['Commission'] = get_col('commission') + get_col('delivery_commission')
    df['Marketing'] = 0.0 
    df['Tax_Adj'] = get_col('subtotal_sales_tax')
    df['Other_Fees'] = get_col('processing_fee') + get_col('merchant_service_fee') + get_col('gh_plus_commission')
    df['Net_Payout'] = get_col('merchant_net_total')
    
    df['Vendor'] = 'Grubhub'
    
    # ä½¿ç”¨åœ°å€ä¼˜å…ˆçš„é—¨åº—æ ‡å‡†åŒ–
    df['Store_Standard'] = df.apply(
        lambda row: normalize_store_grubhub(
            row.get('store_number', ''), 
            row.get('street_address', '')
        ), axis=1
    )
    
    result = df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout']]
    return result, f"âœ… Grubhub: æˆåŠŸå¤„ç† {len(result)} æ¡è®°å½•{warning_msg}"

# ==========================================
# ğŸ–¥ï¸ STREAMLIT UI
# ==========================================

# --- Logo & Header ---
st.markdown(f"<h1 style='color:{luckin_blue};'>â˜• luckin coffee</h1>", unsafe_allow_html=True)
st.markdown("## è´¢åŠ¡å¯¹è´¦è‡ªåŠ¨åŒ–å¹³å° (Financial Reconciliation)")
st.markdown("---")

# --- ä¾§è¾¹æ ï¼šè¯´æ˜æ–‡æ¡£ ---
with st.sidebar:
    st.header("ğŸ“˜ ä½¿ç”¨è¯´æ˜")
    st.info("""
    **ç¬¬ä¸€æ­¥ï¼š** ä¸Šä¼  UberEats, DoorDash, Grubhub çš„æœˆåº¦ CSV è´¦å•ã€‚
    
    **ç¬¬äºŒæ­¥ï¼š** ç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…æ´—æ•°æ®ã€ç»Ÿä¸€åº—é“ºåç§°ã€å¹¶æŒ‰è´¢åŠ¡ç§‘ç›®æ‹†è§£è´¹ç”¨ã€‚
    
    **ç¬¬ä¸‰æ­¥ï¼š** ä¸‹è½½ Excel å¯¹è´¦å•ï¼Œè¿›è¡Œå·®å¼‚è°ƒèŠ‚ã€‚
    """)
    
    st.markdown("### ğŸ’¡ è®¡ç®—é€»è¾‘è¯´æ˜")
    st.markdown("""
    *   **é”€å”®æ€»é¢**: è®¢å•åŸæœ¬é‡‘é¢ (Gross Sales)
    *   **å•†å®¶æŠ˜æ‰£**: ç”±æˆ‘ä»¬æ‰¿æ‹…çš„ä¿ƒé”€æˆæœ¬ (Promo)
    *   **å‡€é”€å”®é¢**: é”€å”®æ€»é¢ + å•†å®¶æŠ˜æ‰£ (å®é™…æ”¶å…¥åŸºç¡€)
    *   **è®¡ç®—å‡€å…¥è´¦**: å‡€é”€å”®é¢ - ä½£é‡‘ - è¥é”€è´¹ - ç¨é‡‘è°ƒæ•´ - å…¶ä»–è´¹ç”¨
    """)
    
    st.markdown("---")
    st.markdown("### ğŸª é—¨åº—IDæ˜ å°„")
    st.markdown("""
    | ID | é—¨åº—åç§° |
    |---|---|
    | US00001 | Broadway (ç™¾è€æ±‡åº—) |
    | US00002 | 6th Ave (ç¬¬å…­å¤§é“åº—) |
    | US00003 | Maiden Lane (æ¢…ç™»å··åº—) |
    | US00004 | 37th St (37è¡—åº—) |
    | US00005 | 8th Ave (ç¬¬å…«å¤§é“åº—) |
    | US00006 | Fulton St (å¯Œå°”é¡¿è¡—åº—) |
    """)

# --- ä¸Šä¼ åŒºåŸŸ ---
st.subheader("ğŸ“‚ è¯·ä¸Šä¼ å¹³å°è´¦å• (CSV)")
col1, col2, col3 = st.columns(3)

with col1:
    uber_file = st.file_uploader("UberEats è´¦å•", type=['csv'])
with col2:
    dd_file = st.file_uploader("DoorDash è´¦å•", type=['csv'])
with col3:
    gh_file = st.file_uploader("Grubhub è´¦å•", type=['csv'])

# --- å¤„ç†æŒ‰é’® ---
st.markdown("<br>", unsafe_allow_html=True)
if st.button("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–å¯¹è´¦å¤„ç†", type="primary"):
    dfs = []
    messages = []
    
    my_bar = st.progress(0)
    
    if uber_file:
        df_u, msg = process_ubereats(uber_file)
        if df_u is not None:
            dfs.append(df_u)
            messages.append(msg)
        else:
            st.error(f"âŒ UberEats æ–‡ä»¶æ ¼å¼é”™è¯¯: {msg}")
    my_bar.progress(30)
            
    if dd_file:
        df_d, msg = process_doordash(dd_file)
        if df_d is not None:
            dfs.append(df_d)
            messages.append(msg)
        else:
            st.error(f"âŒ DoorDash æ–‡ä»¶æ ¼å¼é”™è¯¯: {msg}")
    my_bar.progress(60)

    if gh_file:
        df_g, msg = process_grubhub(gh_file)
        if df_g is not None:
            dfs.append(df_g)
            messages.append(msg)
        else:
            st.error(f"âŒ Grubhub æ–‡ä»¶æ ¼å¼é”™è¯¯: {msg}")
    my_bar.progress(90)

    if not dfs:
        st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæœ‰æ•ˆçš„ CSV æ–‡ä»¶ã€‚")
        my_bar.empty()
    else:
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        for msg in messages:
            if "âš ï¸" in msg:
                st.warning(msg)
            else:
                st.success(msg)
        
        # æ ¸å¿ƒå¤„ç†é€»è¾‘
        master_df = pd.concat(dfs, ignore_index=True)
        
        summary = master_df.groupby(['Vendor', 'Store_Standard'])[[ 
            'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout'
        ]].sum().reset_index()
        
        # æ’å…¥å‡€é”€å”®é¢
        summary.insert(4, 'Net_Sales', summary['Gross_Sales'] + summary['Merchant_Promo'])
        
        # é‡å‘½ååˆ—ä¸ºä¸­æ–‡
        chinese_cols = {
            'Vendor': 'å¹³å°',
            'Store_Standard': 'æ ‡å‡†åº—å',
            'Gross_Sales': 'é”€å”®æ€»é¢',
            'Merchant_Promo': 'å•†å®¶æ‰¿æ‹…æŠ˜æ‰£',
            'Net_Sales': 'å‡€é”€å”®é¢',
            'Commission': 'ä½£é‡‘',
            'Marketing': 'è¥é”€/å¹¿å‘Šè´¹',
            'Tax_Adj': 'ç¨é‡‘è°ƒæ•´',
            'Other_Fees': 'å…¶ä»–è´¹ç”¨',
            'Net_Payout': 'è®¡ç®—å‡€å…¥è´¦'
        }
        display_df = summary.rename(columns=chinese_cols)
        
        my_bar.progress(100)
        
        # --- ç»“æœå±•ç¤ºåŒº ---
        st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼")
        
        # æ±‡æ€»æŒ‡æ ‡
        st.subheader("ğŸ“Š æ±‡æ€»æŒ‡æ ‡")
        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
        with col_m1:
            st.metric("æ€»é”€å”®é¢", f"${display_df['é”€å”®æ€»é¢'].sum():,.2f}")
        with col_m2:
            st.metric("æ€»ä½£é‡‘æ”¯å‡º", f"${abs(display_df['ä½£é‡‘'].sum()):,.2f}")
        with col_m3:
            st.metric("æ€»å‡€å…¥è´¦", f"${display_df['è®¡ç®—å‡€å…¥è´¦'].sum():,.2f}")
        with col_m4:
            unique_stores = display_df['æ ‡å‡†åº—å'].nunique()
            st.metric("æ´»è·ƒé—¨åº—æ•°", f"{unique_stores}")
        
        st.subheader("ğŸ“‹ è´¹ç”¨æ‹†è§£æ˜ç»† (Fee Breakdown)")
        format_dict = {k: "${:,.2f}" for k in chinese_cols.values() if k not in ['å¹³å°', 'æ ‡å‡†åº—å']}
        st.dataframe(display_df.style.format(format_dict), use_container_width=True)

        # --- Excel ç”Ÿæˆ ---
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            wb = writer.book
            
            fmt_header = wb.add_format({
                'bold': True, 'bg_color': '#0022AB', 'font_color': 'white', 
                'border': 1, 'align': 'center', 'valign': 'vcenter'
            })
            fmt_currency = wb.add_format({'num_format': '$#,##0.00'})
            fmt_currency_red = wb.add_format({'num_format': '$#,##0.00', 'font_color': '#9C0006'})
            fmt_input = wb.add_format({'bg_color': '#FFFFCC', 'border': 1, 'num_format': '$#,##0.00'})
            fmt_bold = wb.add_format({'bold': True, 'border': 1, 'num_format': '$#,##0.00'})

            # Sheet 1: è´¹ç”¨æ‹†è§£
            s1_name = 'è´¹ç”¨æ‹†è§£æ˜ç»†'
            display_df.to_excel(writer, sheet_name=s1_name, index=False, startrow=1)
            ws1 = writer.sheets[s1_name]
            
            for col, h in enumerate(display_df.columns):
                ws1.write(0, col, h, fmt_header)
            
            ws1.set_column('A:A', 12)
            ws1.set_column('B:B', 35)
            ws1.set_column('C:J', 15, fmt_currency)
            ws1.set_column('D:D', 15, fmt_currency_red)
            ws1.set_column('F:I', 15, fmt_currency_red)
            ws1.set_column('J:J', 16, fmt_bold)

            # Sheet 2: é“¶è¡Œå¯¹è´¦è¡¨
            s2_name = 'é“¶è¡Œå­˜æ¬¾æ ¸å¯¹'
            recon_view = display_df[['å¹³å°', 'æ ‡å‡†åº—å', 'è®¡ç®—å‡€å…¥è´¦']].copy()
            recon_view.to_excel(writer, sheet_name=s2_name, index=False, startrow=1)
            ws2 = writer.sheets[s2_name]
            
            recon_headers = ['å¹³å°', 'æ ‡å‡†åº—å', 'è®¡ç®—å‡€å…¥è´¦ (A)', 'é“¶è¡Œå®é™…å…¥è´¦ (B) [è¯·å¡«å…¥]', 'å¹³å°éšè—/å‘¨æœŸè´¹ç”¨ (C) [è¯·å¡«å…¥]', 'æœ€ç»ˆå·®å¼‚ (A-B+C)']
            for col, h in enumerate(recon_headers):
                ws2.write(0, col, h, fmt_header)

            ws2.set_column('A:A', 12)
            ws2.set_column('B:B', 35)
            ws2.set_column('C:C', 18, fmt_currency)
            ws2.set_column('D:E', 25, fmt_input)
            ws2.set_column('F:F', 18, fmt_bold)

            for i in range(2, len(recon_view) + 2):
                ws2.write_formula(f'F{i}', f'=C{i}-D{i}+E{i}', fmt_bold)
            
            # Sheet 3: é—¨åº—æ˜ å°„å‚è€ƒ
            s3_name = 'é—¨åº—IDå‚è€ƒ'
            store_ref = pd.DataFrame([
                {'é—¨åº—ID': k, 'é—¨åº—åç§°': v.split(' - ')[1] if ' - ' in v else v} 
                for k, v in STORE_ID_DISPLAY.items()
            ])
            store_ref.to_excel(writer, sheet_name=s3_name, index=False, startrow=1)
            ws3 = writer.sheets[s3_name]
            for col, h in enumerate(store_ref.columns):
                ws3.write(0, col, h, fmt_header)
            ws3.set_column('A:A', 12)
            ws3.set_column('B:B', 30)
                
        output.seek(0)
        
        # --- ä¸‹è½½åŒº & åç»­æŒ‡å¼• ---
        col_download, col_guide = st.columns([1, 2])
        
        with col_download:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Excel å¯¹è´¦åº•ç¨¿",
                data=output,
                file_name="Luckin_Finance_Reconciliation_Report.xlsx",
                mime="application/vnd.ms-excel"
            )
        
        with col_guide:
            st.info("""
            **ğŸ‘©â€ğŸ’» ä¼šè®¡å›¢é˜Ÿåç»­æ“ä½œæŒ‡å¼• (Next Steps):**
            
            1.  **ä¸‹è½½æ–‡ä»¶**: ç‚¹å‡»å·¦ä¾§æŒ‰é’®ä¿å­˜ Excel æ–‡ä»¶ã€‚
            2.  **æ‰“å¼€ Sheet 2 (é“¶è¡Œå­˜æ¬¾æ ¸å¯¹)**:
                *   **é»„è‰²åˆ— D**: å¡«å…¥é“¶è¡Œæµæ°´ä¸­å®é™…æ”¶åˆ°çš„é‡‘é¢ã€‚
                *   **é»„è‰²åˆ— E**: å¡«å…¥ CSV ä¸­æœªä½“ç°çš„å¹³å°è°ƒæ•´é¡¹ï¼ˆå¦‚ UberEats çš„ EzRewardã€Membership Feeï¼Œæˆ– DoorDash çš„è·¨å‘¨æœŸæ‰“æ¬¾ï¼‰ã€‚
            3.  **æ£€æŸ¥å·®å¼‚**: ç¡®ä¿æœ€åä¸€åˆ— "æœ€ç»ˆå·®å¼‚" å½’é›¶æˆ–åœ¨å…è®¸è¯¯å·®èŒƒå›´å†…ã€‚
            4.  **å…¥è´¦**: ä½¿ç”¨ Sheet 1 çš„æ˜ç»†æ•°æ®å½•å…¥ ERP ç³»ç»Ÿã€‚
            """)

# --- é¡µè„š ---
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 1rem;'>
    <p>ç‘å¹¸å’–å•¡è´¢åŠ¡å¯¹è´¦ç³»ç»Ÿ v2.0</p>
    <p style='font-size: 0.9rem;'>âœ… é—¨åº—æ˜ å°„å·²ä¿®å¤ (US00001-US00006) â€¢ æ”¯æŒ UberEats / DoorDash / Grubhub</p>
</div>
""", unsafe_allow_html=True)
