import streamlit as st
import pandas as pd
import io
import csv
from PIL import Image

# ==========================================
# ğŸ¨ é¡µé¢é…ç½®ä¸ CSS æ ·å¼ (Luckin é£æ ¼)
# ==========================================
st.set_page_config(page_title="ç‘å¹¸å’–å•¡è´¢åŠ¡å¯¹è´¦ç³»ç»Ÿ", layout="wide", page_icon="â˜•")

# ç‘å¹¸è“: #0022AB (è¿‘ä¼¼)
luckin_blue = "#0022AB"

st.markdown(f"""
    <style>
    /* å…¨å±€å­—ä½“ä¼˜åŒ– */
    .main {{
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
    }}
    /* æŒ‰é’®æ ·å¼è¦†ç›– - ç‘å¹¸è“ */
    .stButton>button {{
        background-color: {luckin_blue};
        color: white;
        border-radius: 5px;
        height: 3em;
        width: 100%;
        font-weight: bold;
        border: none;
    }}
    .stButton>button:hover {{
        background-color: #00187A; /* æ·±ä¸€ç‚¹çš„è“è‰² */
        color: white;
    }}
    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3 {{
        color: #333333;
    }}
    /* æç¤ºæ¡†æ ·å¼ */
    .stAlert {{
        background-color: #EEF4FF;
        border-left: 5px solid {luckin_blue};
    }}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# ğŸ§  æ ¸å¿ƒé€»è¾‘ & æ˜ å°„
# ==========================================

STORE_MAP = {
    'broadway': '755 (Broadway)',
    '755':      '755 (Broadway)',
    'fulton':   '102 (Fulton St)',
    '102':      '102 (Fulton St)',
    '6th':      '800 (6th Ave)',
    '800':      '800 (6th Ave)',
    '8th':      '901 (8th Ave)',
    '901':      '901 (8th Ave)',
    'maiden':   '100 (Maiden Ln)',
    '100':      '100 (Maiden Ln)'
}

def normalize_store(raw_text):
    if pd.isna(raw_text): return 'æœªçŸ¥é—¨åº—'
    text_lower = str(raw_text).lower()
    for key, standard_name in STORE_MAP.items():
        if key in text_lower:
            return standard_name
    return raw_text

def clean_num(x):
    if isinstance(x, (int, float)): return x
    try:
        clean = str(x).replace(',', '').replace('$', '').replace(' ', '').strip()
        return float(clean) if clean else 0.0
    except: return 0.0

def find_header_row(uploaded_file, target_columns):
    uploaded_file.seek(0)
    try:
        content = uploaded_file.getvalue().decode('utf-8', errors='replace').splitlines()
        reader = csv.reader(content)
        for i, row in enumerate(reader):
            clean_row = [str(x).strip() for x in row]
            matches = sum(1 for col in target_columns if col in clean_row)
            if matches >= 2:
                uploaded_file.seek(0)
                return i
    except Exception:
        return None
    return None

# ==========================================
# ğŸŸ¦ å¹³å°æ•°æ®å¤„ç† (ä¿æŒé€»è¾‘ä¸å˜ï¼Œä¼˜åŒ–è¾“å‡º)
# ==========================================

def process_ubereats(uploaded_file):
    target_cols = ['é¤å…åç§°', 'é”€å”®é¢ï¼ˆä¸å«ç¨è´¹ï¼‰', 'å¹³å°æœåŠ¡è´¹']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None: return None

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    def get_col(col_name):
        return df[col_name].apply(clean_num) if col_name in df.columns else 0.0

    df['Gross_Sales'] = get_col('é”€å”®é¢ï¼ˆä¸å«ç¨è´¹ï¼‰')
    df['Merchant_Promo'] = get_col('å•†å“ä¼˜æƒ ï¼ˆå«ç¨ï¼‰') 
    df['Commission'] = get_col('å¹³å°æœåŠ¡è´¹')
    df['Marketing'] = get_col('è¥é”€è°ƒæ•´é¢') + get_col('å¹¿å‘Šæ”¯å‡º')
    df['Tax_Adj'] = get_col('é”€å”®é¢ç¨è´¹') + get_col('å¹³å°ä»£ç¼´ç¨')
    df['Other_Fees'] = get_col('è®¢å•é”™è¯¯è°ƒæ•´é¢') + get_col('æ´¾é€ç½‘ç»œè´¹')
    df['Net_Payout'] = get_col('æ”¶å…¥æ€»é¢')
    
    df['Vendor'] = 'UberEats'
    df['Store_Standard'] = df['é¤å…åç§°'].apply(normalize_store)
    
    return df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout']]

def process_doordash(uploaded_file):
    target_cols = ['åº—é“ºåç§°', 'å°è®¡', 'ä½£é‡‘']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None: return None

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    def get_col(col_name):
        matches = [c for c in df.columns if col_name in c]
        if matches: return df[matches[0]].apply(clean_num)
        return 0.0

    df['Gross_Sales'] = get_col('å°è®¡')
    df['Merchant_Promo'] = get_col('ç”±æ‚¨å‡ºèµ„') 
    df['Commission'] = get_col('ä½£é‡‘')
    df['Marketing'] = get_col('è¥é”€è´¹') + get_col('è¥é”€ç§¯åˆ†')
    df['Tax_Adj'] = get_col('ç¨æ¬¾å°è®¡')
    df['Other_Fees'] = get_col('é”™è¯¯è´¹ç”¨') + get_col('è°ƒæ•´')
    df['Net_Payout'] = get_col('å‡€æ€»è®¡')
    
    df['Vendor'] = 'DoorDash'
    df['Store_Standard'] = df['åº—é“ºåç§°'].apply(normalize_store)
    
    return df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout']]

def process_grubhub(uploaded_file):
    target_cols = ['store_name', 'subtotal', 'commission']
    header_row = find_header_row(uploaded_file, target_cols)
    if header_row is None: return None

    df = pd.read_csv(uploaded_file, header=header_row)
    df.columns = df.columns.str.strip()
    
    def get_col(col_name):
        return df[col_name].apply(clean_num) if col_name in df.columns else 0.0

    df['Gross_Sales'] = get_col('subtotal')
    df['Merchant_Promo'] = get_col('merchant_funded_promotion') + get_col('merchant_funded_loyalty')
    df['Commission'] = get_col('commission') + get_col('delivery_commission')
    df['Marketing'] = 0.0 
    df['Tax_Adj'] = 0.0 
    df['Other_Fees'] = get_col('processing_fee') + get_col('merchant_service_fee')
    df['Net_Payout'] = get_col('merchant_net_total')
    
    df['Vendor'] = 'Grubhub'
    df['store_info'] = df['store_name'].astype(str) + " " + df.get('street_address', '').astype(str)
    df['Store_Standard'] = df['store_info'].apply(normalize_store)
    
    return df[['Vendor', 'Store_Standard', 'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout']]

# ==========================================
# ğŸ–¥ï¸ STREAMLIT UI
# ==========================================

# --- Logo & Header ---
try:
    # å°è¯•åŠ è½½ logo (è¯·ç¡®ä¿æ–‡ä»¶åä¸º logo.png æˆ– logo.jpg ä¸”åœ¨åŒä¸€ç›®å½•)
    st.image("logo.png", width=150) 
except:
    # å¦‚æœæ²¡æœ‰ logo æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ–‡å­—å¤‡é€‰
    st.markdown(f"<h1 style='color:{luckin_blue};'>luckin coffee</h1>", unsafe_allow_html=True)

st.markdown("## è´¢åŠ¡å¯¹è´¦è‡ªåŠ¨åŒ–å¹³å° (Financial Reconciliation)")
st.markdown("---")

# --- ä¾§è¾¹æ ï¼šè¯´æ˜æ–‡æ¡£ ---
with st.sidebar:
    st.header("ğŸ“˜ ä½¿ç”¨è¯´æ˜")
    st.info("""
    **ç¬¬ä¸€æ­¥ï¼š** ä¸Šä¼  UberEats, DoorDash, Grubhub çš„æœˆåº¦ CSV è´¦å•ã€‚
    
    **ç¬¬äºŒæ­¥ï¼š** ç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…æ´—æ•°æ®ã€ç»Ÿä¸€åº—é“ºåç§°ã€å¹¶æŒ‰è´¢åŠ¡ç§‘ç›®æ‹†è§£è´¹ç”¨ã€‚
    
    **ç¬¬ä¸‰æ­¥ï¼š** ä¸‹è½½ Excel å¯¹è´¦å•ï¼Œè¿›è¡Œå·®å¼‚è°ƒèŠ‚ã€‚
    """)
    
    st.markdown("### ğŸ’¡ è®¡ç®—é€»è¾‘è¯´æ˜")
    st.markdown("""
    *   **é”€å”®æ€»é¢**: è®¢å•åŸæœ¬é‡‘é¢ (Gross Sales)
    *   **å•†å®¶æŠ˜æ‰£**: ç”±æˆ‘ä»¬æ‰¿æ‹…çš„ä¿ƒé”€æˆæœ¬ (Promo)
    *   **å‡€é”€å”®é¢**: é”€å”®æ€»é¢ + å•†å®¶æŠ˜æ‰£ (å®é™…æ”¶å…¥åŸºç¡€)
    *   **è®¡ç®—å‡€å…¥è´¦**: å‡€é”€å”®é¢ - ä½£é‡‘ - è¥é”€è´¹ - ç¨é‡‘è°ƒæ•´ - å…¶ä»–è´¹ç”¨
    """)

# --- ä¸Šä¼ åŒºåŸŸ ---
st.subheader("ğŸ“‚ è¯·ä¸Šä¼ å¹³å°è´¦å• (CSV)")
col1, col2, col3 = st.columns(3)

with col1:
    uber_file = st.file_uploader("UberEats è´¦å•", type=['csv'])
with col2:
    dd_file = st.file_uploader("DoorDash è´¦å•", type=['csv'])
with col3:
    gh_file = st.file_uploader("Grubhub è´¦å•", type=['csv'])

# --- å¤„ç†æŒ‰é’® ---
st.markdown("<br>", unsafe_allow_html=True)
if st.button("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–å¯¹è´¦å¤„ç†", type="primary"):
    dfs = []
    
    # è¿›åº¦æ¡
    my_bar = st.progress(0)
    
    if uber_file:
        df_u = process_ubereats(uber_file)
        if df_u is not None: dfs.append(df_u)
        else: st.error("âŒ UberEats æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¡¨å¤´ã€‚")
    my_bar.progress(30)
            
    if dd_file:
        df_d = process_doordash(dd_file)
        if df_d is not None: dfs.append(df_d)
        else: st.error("âŒ DoorDash æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¡¨å¤´ã€‚")
    my_bar.progress(60)

    if gh_file:
        df_g = process_grubhub(gh_file)
        if df_g is not None: dfs.append(df_g)
        else: st.error("âŒ Grubhub æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¡¨å¤´ã€‚")
    my_bar.progress(90)

    if not dfs:
        st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæœ‰æ•ˆçš„ CSV æ–‡ä»¶ã€‚")
        my_bar.empty()
    else:
        # æ ¸å¿ƒå¤„ç†é€»è¾‘
        master_df = pd.concat(dfs, ignore_index=True)
        
        summary = master_df.groupby(['Vendor', 'Store_Standard'])[[ 
            'Gross_Sales', 'Merchant_Promo', 'Commission', 'Marketing', 'Tax_Adj', 'Other_Fees', 'Net_Payout'
        ]].sum().reset_index()
        
        # æ’å…¥å‡€é”€å”®é¢
        summary.insert(4, 'Net_Sales', summary['Gross_Sales'] + summary['Merchant_Promo'])
        
        # é‡å‘½ååˆ—ä¸ºä¸­æ–‡ï¼ˆç”¨äºå±•ç¤ºå’Œå¯¼å‡ºï¼‰
        chinese_cols = {
            'Vendor': 'å¹³å°',
            'Store_Standard': 'æ ‡å‡†åº—å',
            'Gross_Sales': 'é”€å”®æ€»é¢',
            'Merchant_Promo': 'å•†å®¶æ‰¿æ‹…æŠ˜æ‰£',
            'Net_Sales': 'å‡€é”€å”®é¢',
            'Commission': 'ä½£é‡‘',
            'Marketing': 'è¥é”€/å¹¿å‘Šè´¹',
            'Tax_Adj': 'ç¨é‡‘è°ƒæ•´',
            'Other_Fees': 'å…¶ä»–è´¹ç”¨',
            'Net_Payout': 'è®¡ç®—å‡€å…¥è´¦'
        }
        display_df = summary.rename(columns=chinese_cols)
        
        my_bar.progress(100)
        
        # --- ç»“æœå±•ç¤ºåŒº ---
        st.success("âœ… æ•°æ®å¤„ç†å®Œæˆï¼")
        
        st.subheader("ğŸ“Š è´¹ç”¨æ‹†è§£é¢„è§ˆ (Fee Breakdown)")
        # æ ¼å¼åŒ–æ˜¾ç¤º
        format_dict = {k: "${:,.2f}" for k in chinese_cols.values() if k not in ['å¹³å°', 'æ ‡å‡†åº—å']}
        st.dataframe(display_df.style.format(format_dict))

        # --- Excel ç”Ÿæˆ ---
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            wb = writer.book
            
            # å®šä¹‰ Excel æ ·å¼
            fmt_header = wb.add_format({
                'bold': True, 'bg_color': '#0022AB', 'font_color': 'white', 
                'border': 1, 'align': 'center', 'valign': 'vcenter'
            })
            fmt_currency = wb.add_format({'num_format': '$#,##0.00'})
            fmt_currency_red = wb.add_format({'num_format': '$#,##0.00', 'font_color': '#9C0006'})
            fmt_input = wb.add_format({'bg_color': '#FFFFCC', 'border': 1, 'num_format': '$#,##0.00'})
            fmt_bold = wb.add_format({'bold': True, 'border': 1, 'num_format': '$#,##0.00'})

            # Sheet 1: è´¹ç”¨æ‹†è§£
            s1_name = 'è´¹ç”¨æ‹†è§£æ˜ç»†'
            display_df.to_excel(writer, sheet_name=s1_name, index=False, startrow=1)
            ws1 = writer.sheets[s1_name]
            
            # å†™å…¥ä¸­æ–‡è¡¨å¤´
            for col, h in enumerate(display_df.columns):
                ws1.write(0, col, h, fmt_header)
            
            ws1.set_column('A:B', 20) # å¹³å°ã€åº—å
            ws1.set_column('C:J', 15, fmt_currency)
            ws1.set_column('D:D', 15, fmt_currency_red) # æŠ˜æ‰£çº¢å­—
            ws1.set_column('F:I', 15, fmt_currency_red) # è´¹ç”¨çº¢å­—
            ws1.set_column('J:J', 16, fmt_bold) # å‡€å…¥è´¦åŠ ç²—

            # Sheet 2: é“¶è¡Œå¯¹è´¦è¡¨
            s2_name = 'é“¶è¡Œå­˜æ¬¾æ ¸å¯¹'
            recon_view = display_df[['å¹³å°', 'æ ‡å‡†åº—å', 'è®¡ç®—å‡€å…¥è´¦']].copy()
            recon_view.to_excel(writer, sheet_name=s2_name, index=False, startrow=1)
            ws2 = writer.sheets[s2_name]
            
            recon_headers = ['å¹³å°', 'æ ‡å‡†åº—å', 'è®¡ç®—å‡€å…¥è´¦ (A)', 'é“¶è¡Œå®é™…å…¥è´¦ (B) [è¯·å¡«å…¥]', 'å¹³å°éšè—/å‘¨æœŸè´¹ç”¨ (C) [è¯·å¡«å…¥]', 'æœ€ç»ˆå·®å¼‚ (A-B+C)']
            for col, h in enumerate(recon_headers):
                ws2.write(0, col, h, fmt_header)

            ws2.set_column('A:B', 20)
            ws2.set_column('C:C', 18, fmt_currency)
            ws2.set_column('D:E', 20, fmt_input) # é»„è‰²å¡«æŠ¥åŒº
            ws2.set_column('F:F', 18, fmt_bold)

            # å†™å…¥å·®å¼‚å…¬å¼
            for i in range(2, len(recon_view) + 2):
                ws2.write_formula(f'F{i}', f'=C{i}-D{i}+E{i}', fmt_bold)
                
        output.seek(0)
        
        # --- ä¸‹è½½åŒº & åç»­æŒ‡å¼• ---
        col_download, col_guide = st.columns([1, 2])
        
        with col_download:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Excel å¯¹è´¦åº•ç¨¿",
                data=output,
                file_name="Luckin_Finance_Reconciliation_Report.xlsx",
                mime="application/vnd.ms-excel"
            )
        
        with col_guide:
            st.info("""
            **ğŸ‘©â€ğŸ’» ä¼šè®¡å›¢é˜Ÿåç»­æ“ä½œæŒ‡å¼• (Next Steps):**
            
            1.  **ä¸‹è½½æ–‡ä»¶**: ç‚¹å‡»å·¦ä¾§æŒ‰é’®ä¿å­˜ Excel æ–‡ä»¶ã€‚
            2.  **æ‰“å¼€ Sheet 2 (é“¶è¡Œå­˜æ¬¾æ ¸å¯¹)**:
                *   **é»„è‰²åˆ— D**: å¡«å…¥é“¶è¡Œæµæ°´ä¸­å®é™…æ”¶åˆ°çš„é‡‘é¢ã€‚
                *   **é»„è‰²åˆ— E**: å¡«å…¥ CSV ä¸­æœªä½“ç°çš„å¹³å°è°ƒæ•´é¡¹ï¼ˆå¦‚ UberEats çš„ EzRewardã€Membership Feeï¼Œæˆ– DoorDash çš„è·¨å‘¨æœŸæ‰“æ¬¾ï¼‰ã€‚
            3.  **æ£€æŸ¥å·®å¼‚**: ç¡®ä¿æœ€åä¸€åˆ— "æœ€ç»ˆå·®å¼‚" å½’é›¶æˆ–åœ¨å…è®¸è¯¯å·®èŒƒå›´å†…ã€‚
            4.  **å…¥è´¦**: ä½¿ç”¨ Sheet 1 çš„æ˜ç»†æ•°æ®å½•å…¥ ERP ç³»ç»Ÿã€‚
            """)
